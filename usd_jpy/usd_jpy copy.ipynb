{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USD JPY Hour Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (100_011, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>date</th><th>open</th><th>high</th><th>low</th><th>close</th><th>volume</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;2008-11-11&nbsp;06:00&quot;</td><td>97.97</td><td>98.06</td><td>97.85</td><td>97.92</td><td>7479</td></tr><tr><td>&quot;2008-11-11&nbsp;07:00&quot;</td><td>97.92</td><td>97.96</td><td>97.62</td><td>97.64</td><td>33880</td></tr><tr><td>&quot;2008-11-11&nbsp;08:00&quot;</td><td>97.64</td><td>97.82</td><td>97.555</td><td>97.785</td><td>35566</td></tr><tr><td>&quot;2008-11-11&nbsp;09:00&quot;</td><td>97.785</td><td>97.98</td><td>97.67</td><td>97.76</td><td>36609</td></tr><tr><td>&quot;2008-11-11&nbsp;10:00&quot;</td><td>97.755</td><td>97.9</td><td>97.605</td><td>97.795</td><td>34606</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;2024-12-04&nbsp;22:00&quot;</td><td>150.525</td><td>150.555</td><td>150.445</td><td>150.505</td><td>972</td></tr><tr><td>&quot;2024-12-04&nbsp;23:00&quot;</td><td>150.518</td><td>150.774</td><td>150.509</td><td>150.547</td><td>10980</td></tr><tr><td>&quot;2024-12-05&nbsp;00:00&quot;</td><td>150.547</td><td>150.547</td><td>150.191</td><td>150.221</td><td>28875</td></tr><tr><td>&quot;2024-12-05&nbsp;01:00&quot;</td><td>150.221</td><td>150.68</td><td>150.185</td><td>150.536</td><td>30694</td></tr><tr><td>&quot;2024-12-05&nbsp;02:00&quot;</td><td>150.536</td><td>150.561</td><td>150.215</td><td>150.333</td><td>24461</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (100_011, 6)\n",
       "┌──────────────────┬─────────┬─────────┬─────────┬─────────┬────────┐\n",
       "│ date             ┆ open    ┆ high    ┆ low     ┆ close   ┆ volume │\n",
       "│ ---              ┆ ---     ┆ ---     ┆ ---     ┆ ---     ┆ ---    │\n",
       "│ str              ┆ f64     ┆ f64     ┆ f64     ┆ f64     ┆ i64    │\n",
       "╞══════════════════╪═════════╪═════════╪═════════╪═════════╪════════╡\n",
       "│ 2008-11-11 06:00 ┆ 97.97   ┆ 98.06   ┆ 97.85   ┆ 97.92   ┆ 7479   │\n",
       "│ 2008-11-11 07:00 ┆ 97.92   ┆ 97.96   ┆ 97.62   ┆ 97.64   ┆ 33880  │\n",
       "│ 2008-11-11 08:00 ┆ 97.64   ┆ 97.82   ┆ 97.555  ┆ 97.785  ┆ 35566  │\n",
       "│ 2008-11-11 09:00 ┆ 97.785  ┆ 97.98   ┆ 97.67   ┆ 97.76   ┆ 36609  │\n",
       "│ 2008-11-11 10:00 ┆ 97.755  ┆ 97.9    ┆ 97.605  ┆ 97.795  ┆ 34606  │\n",
       "│ …                ┆ …       ┆ …       ┆ …       ┆ …       ┆ …      │\n",
       "│ 2024-12-04 22:00 ┆ 150.525 ┆ 150.555 ┆ 150.445 ┆ 150.505 ┆ 972    │\n",
       "│ 2024-12-04 23:00 ┆ 150.518 ┆ 150.774 ┆ 150.509 ┆ 150.547 ┆ 10980  │\n",
       "│ 2024-12-05 00:00 ┆ 150.547 ┆ 150.547 ┆ 150.191 ┆ 150.221 ┆ 28875  │\n",
       "│ 2024-12-05 01:00 ┆ 150.221 ┆ 150.68  ┆ 150.185 ┆ 150.536 ┆ 30694  │\n",
       "│ 2024-12-05 02:00 ┆ 150.536 ┆ 150.561 ┆ 150.215 ┆ 150.333 ┆ 24461  │\n",
       "└──────────────────┴─────────┴─────────┴─────────┴─────────┴────────┘"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Read the CSV file into a Polars DataFrame\n",
    "file_path = \"USDJPY60.csv\"  # Replace with your CSV file path\n",
    "df = pl.read_csv(file_path, separator=\"\\t\", has_header=False)\n",
    "\n",
    "# Rename columns to match the expected structure\n",
    "df.columns = [\"date\", \"open\", \"high\", \"low\", \"close\", \"volume\"]\n",
    "\n",
    "# Display the first few rows\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean + Features Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (99_988, 34)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>date</th><th>open</th><th>high</th><th>low</th><th>close</th><th>volume</th><th>prev_open</th><th>prev_high</th><th>prev_low</th><th>prev_close</th><th>prev_volume</th><th>open_change</th><th>high_change</th><th>low_change</th><th>close_change</th><th>open_pct_change</th><th>close_pct_change</th><th>rolling_avg_open_3h</th><th>rolling_avg_close_5h</th><th>rolling_max_high_3h</th><th>rolling_min_low_3h</th><th>volume_change</th><th>volume_ma_3h</th><th>hour_of_day</th><th>day_of_week</th><th>high_low_ratio</th><th>close_open_ratio</th><th>max_close_4h</th><th>max_close_8h</th><th>max_close_12h</th><th>max_close_24h</th><th>diff_to_max_close</th><th>diff_to_min_close</th><th>next_close</th></tr><tr><td>datetime[μs]</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>i64</td><td>f64</td><td>i8</td><td>i8</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>2008-11-12&nbsp;05:00:00</td><td>97.685</td><td>97.74</td><td>97.555</td><td>97.7</td><td>18396</td><td>97.57</td><td>97.765</td><td>97.57</td><td>97.685</td><td>21204</td><td>0.115</td><td>-0.025</td><td>-0.015</td><td>0.015</td><td>0.117864</td><td>0.015355</td><td>97.68</td><td>97.714</td><td>97.84</td><td>97.545</td><td>-2808</td><td>21443.333333</td><td>5</td><td>3</td><td>1.001896</td><td>1.000154</td><td>97.795</td><td>97.825</td><td>97.855</td><td>97.975</td><td>-64.236</td><td>22.021</td><td>97.77</td></tr><tr><td>2008-11-12&nbsp;06:00:00</td><td>97.7</td><td>97.815</td><td>97.67</td><td>97.77</td><td>16598</td><td>97.685</td><td>97.74</td><td>97.555</td><td>97.7</td><td>18396</td><td>0.015</td><td>0.075</td><td>0.115</td><td>0.07</td><td>0.015355</td><td>0.071648</td><td>97.651667</td><td>97.703</td><td>97.815</td><td>97.555</td><td>-1798</td><td>18732.666667</td><td>6</td><td>3</td><td>1.001485</td><td>1.000716</td><td>97.77</td><td>97.825</td><td>97.855</td><td>97.975</td><td>-64.166</td><td>22.091</td><td>97.945</td></tr><tr><td>2008-11-12&nbsp;07:00:00</td><td>97.755</td><td>98.07</td><td>97.72</td><td>97.945</td><td>38507</td><td>97.7</td><td>97.815</td><td>97.67</td><td>97.77</td><td>16598</td><td>0.055</td><td>0.255</td><td>0.05</td><td>0.175</td><td>0.056295</td><td>0.178992</td><td>97.713333</td><td>97.733</td><td>98.07</td><td>97.555</td><td>21909</td><td>24500.333333</td><td>7</td><td>3</td><td>1.003582</td><td>1.001944</td><td>97.945</td><td>97.945</td><td>97.945</td><td>97.975</td><td>-63.991</td><td>22.266</td><td>97.565</td></tr><tr><td>2008-11-12&nbsp;08:00:00</td><td>97.955</td><td>97.995</td><td>97.51</td><td>97.565</td><td>41159</td><td>97.755</td><td>98.07</td><td>97.72</td><td>97.945</td><td>38507</td><td>0.2</td><td>-0.075</td><td>-0.21</td><td>-0.38</td><td>0.204593</td><td>-0.387973</td><td>97.803333</td><td>97.733</td><td>98.07</td><td>97.51</td><td>2652</td><td>32088.0</td><td>8</td><td>3</td><td>1.004974</td><td>0.996019</td><td>97.945</td><td>97.945</td><td>97.945</td><td>97.975</td><td>-64.371</td><td>21.886</td><td>97.31</td></tr><tr><td>2008-11-12&nbsp;09:00:00</td><td>97.56</td><td>97.75</td><td>97.195</td><td>97.31</td><td>41104</td><td>97.955</td><td>97.995</td><td>97.51</td><td>97.565</td><td>41159</td><td>-0.395</td><td>-0.245</td><td>-0.315</td><td>-0.255</td><td>-0.403246</td><td>-0.261364</td><td>97.756667</td><td>97.658</td><td>98.07</td><td>97.195</td><td>-55</td><td>40256.666667</td><td>9</td><td>3</td><td>1.00571</td><td>0.997437</td><td>97.945</td><td>97.945</td><td>97.945</td><td>97.975</td><td>-64.626</td><td>21.631</td><td>97.26</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>2024-12-04&nbsp;22:00:00</td><td>150.525</td><td>150.555</td><td>150.445</td><td>150.505</td><td>972</td><td>150.519</td><td>150.659</td><td>150.484</td><td>150.539</td><td>8303</td><td>0.006</td><td>-0.104</td><td>-0.039</td><td>-0.034</td><td>0.003986</td><td>-0.022586</td><td>150.494</td><td>150.4822</td><td>150.67</td><td>150.436</td><td>-7331</td><td>11390.666667</td><td>22</td><td>3</td><td>1.000731</td><td>0.999867</td><td>150.539</td><td>150.539</td><td>151.17</td><td>151.17</td><td>-11.431</td><td>74.826</td><td>150.547</td></tr><tr><td>2024-12-04&nbsp;23:00:00</td><td>150.518</td><td>150.774</td><td>150.509</td><td>150.547</td><td>10980</td><td>150.525</td><td>150.555</td><td>150.445</td><td>150.505</td><td>972</td><td>-0.007</td><td>0.219</td><td>0.064</td><td>0.042</td><td>-0.00465</td><td>0.027906</td><td>150.520667</td><td>150.51</td><td>150.774</td><td>150.445</td><td>10008</td><td>6751.666667</td><td>23</td><td>3</td><td>1.001761</td><td>1.000193</td><td>150.547</td><td>150.547</td><td>151.17</td><td>151.17</td><td>-11.389</td><td>74.868</td><td>150.221</td></tr><tr><td>2024-12-05&nbsp;00:00:00</td><td>150.547</td><td>150.547</td><td>150.191</td><td>150.221</td><td>28875</td><td>150.518</td><td>150.774</td><td>150.509</td><td>150.547</td><td>10980</td><td>0.029</td><td>-0.227</td><td>-0.318</td><td>-0.326</td><td>0.019267</td><td>-0.216544</td><td>150.53</td><td>150.4666</td><td>150.774</td><td>150.191</td><td>17895</td><td>13609.0</td><td>0</td><td>4</td><td>1.00237</td><td>0.997835</td><td>150.547</td><td>150.547</td><td>151.071</td><td>151.17</td><td>-11.715</td><td>74.542</td><td>150.536</td></tr><tr><td>2024-12-05&nbsp;01:00:00</td><td>150.221</td><td>150.68</td><td>150.185</td><td>150.536</td><td>30694</td><td>150.547</td><td>150.547</td><td>150.191</td><td>150.221</td><td>28875</td><td>-0.326</td><td>0.133</td><td>-0.006</td><td>0.315</td><td>-0.216544</td><td>0.209691</td><td>150.428667</td><td>150.4696</td><td>150.774</td><td>150.185</td><td>1819</td><td>23516.333333</td><td>1</td><td>4</td><td>1.003296</td><td>1.002097</td><td>150.547</td><td>150.547</td><td>150.848</td><td>151.17</td><td>-11.4</td><td>74.857</td><td>150.333</td></tr><tr><td>2024-12-05&nbsp;02:00:00</td><td>150.536</td><td>150.561</td><td>150.215</td><td>150.333</td><td>24461</td><td>150.221</td><td>150.68</td><td>150.185</td><td>150.536</td><td>30694</td><td>0.315</td><td>-0.119</td><td>0.03</td><td>-0.203</td><td>0.209691</td><td>-0.134851</td><td>150.434667</td><td>150.4284</td><td>150.68</td><td>150.185</td><td>-6233</td><td>28010.0</td><td>2</td><td>4</td><td>1.002303</td><td>0.998651</td><td>150.547</td><td>150.547</td><td>150.547</td><td>151.17</td><td>-11.603</td><td>74.654</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (99_988, 34)\n",
       "┌────────────┬─────────┬─────────┬─────────┬───┬────────────┬────────────┬────────────┬────────────┐\n",
       "│ date       ┆ open    ┆ high    ┆ low     ┆ … ┆ max_close_ ┆ diff_to_ma ┆ diff_to_mi ┆ next_close │\n",
       "│ ---        ┆ ---     ┆ ---     ┆ ---     ┆   ┆ 24h        ┆ x_close    ┆ n_close    ┆ ---        │\n",
       "│ datetime[μ ┆ f64     ┆ f64     ┆ f64     ┆   ┆ ---        ┆ ---        ┆ ---        ┆ f64        │\n",
       "│ s]         ┆         ┆         ┆         ┆   ┆ f64        ┆ f64        ┆ f64        ┆            │\n",
       "╞════════════╪═════════╪═════════╪═════════╪═══╪════════════╪════════════╪════════════╪════════════╡\n",
       "│ 2008-11-12 ┆ 97.685  ┆ 97.74   ┆ 97.555  ┆ … ┆ 97.975     ┆ -64.236    ┆ 22.021     ┆ 97.77      │\n",
       "│ 05:00:00   ┆         ┆         ┆         ┆   ┆            ┆            ┆            ┆            │\n",
       "│ 2008-11-12 ┆ 97.7    ┆ 97.815  ┆ 97.67   ┆ … ┆ 97.975     ┆ -64.166    ┆ 22.091     ┆ 97.945     │\n",
       "│ 06:00:00   ┆         ┆         ┆         ┆   ┆            ┆            ┆            ┆            │\n",
       "│ 2008-11-12 ┆ 97.755  ┆ 98.07   ┆ 97.72   ┆ … ┆ 97.975     ┆ -63.991    ┆ 22.266     ┆ 97.565     │\n",
       "│ 07:00:00   ┆         ┆         ┆         ┆   ┆            ┆            ┆            ┆            │\n",
       "│ 2008-11-12 ┆ 97.955  ┆ 97.995  ┆ 97.51   ┆ … ┆ 97.975     ┆ -64.371    ┆ 21.886     ┆ 97.31      │\n",
       "│ 08:00:00   ┆         ┆         ┆         ┆   ┆            ┆            ┆            ┆            │\n",
       "│ 2008-11-12 ┆ 97.56   ┆ 97.75   ┆ 97.195  ┆ … ┆ 97.975     ┆ -64.626    ┆ 21.631     ┆ 97.26      │\n",
       "│ 09:00:00   ┆         ┆         ┆         ┆   ┆            ┆            ┆            ┆            │\n",
       "│ …          ┆ …       ┆ …       ┆ …       ┆ … ┆ …          ┆ …          ┆ …          ┆ …          │\n",
       "│ 2024-12-04 ┆ 150.525 ┆ 150.555 ┆ 150.445 ┆ … ┆ 151.17     ┆ -11.431    ┆ 74.826     ┆ 150.547    │\n",
       "│ 22:00:00   ┆         ┆         ┆         ┆   ┆            ┆            ┆            ┆            │\n",
       "│ 2024-12-04 ┆ 150.518 ┆ 150.774 ┆ 150.509 ┆ … ┆ 151.17     ┆ -11.389    ┆ 74.868     ┆ 150.221    │\n",
       "│ 23:00:00   ┆         ┆         ┆         ┆   ┆            ┆            ┆            ┆            │\n",
       "│ 2024-12-05 ┆ 150.547 ┆ 150.547 ┆ 150.191 ┆ … ┆ 151.17     ┆ -11.715    ┆ 74.542     ┆ 150.536    │\n",
       "│ 00:00:00   ┆         ┆         ┆         ┆   ┆            ┆            ┆            ┆            │\n",
       "│ 2024-12-05 ┆ 150.221 ┆ 150.68  ┆ 150.185 ┆ … ┆ 151.17     ┆ -11.4      ┆ 74.857     ┆ 150.333    │\n",
       "│ 01:00:00   ┆         ┆         ┆         ┆   ┆            ┆            ┆            ┆            │\n",
       "│ 2024-12-05 ┆ 150.536 ┆ 150.561 ┆ 150.215 ┆ … ┆ 151.17     ┆ -11.603    ┆ 74.654     ┆ null       │\n",
       "│ 02:00:00   ┆         ┆         ┆         ┆   ┆            ┆            ┆            ┆            │\n",
       "└────────────┴─────────┴─────────┴─────────┴───┴────────────┴────────────┴────────────┴────────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Load the DataFrame (assuming it is already loaded as df)\n",
    "\n",
    "df_features = df.clone()\n",
    "\n",
    "# Ensure 'date' is in datetime format\n",
    "df_features = df_features.with_columns(\n",
    "    pl.col(\"date\").str.strptime(pl.Datetime).alias(\"date\")\n",
    ")\n",
    "\n",
    "# Create lagged features\n",
    "df_features = df_features.with_columns(\n",
    "    pl.col('open').shift(1).alias('prev_open'),\n",
    "    pl.col('high').shift(1).alias('prev_high'),\n",
    "    pl.col('low').shift(1).alias('prev_low'),\n",
    "    pl.col('close').shift(1).alias('prev_close'),\n",
    "    pl.col('volume').shift(1).alias('prev_volume')\n",
    ")\n",
    "\n",
    "# Calculate changes\n",
    "df_features = df_features.with_columns(\n",
    "    (pl.col('open') - pl.col('prev_open')).alias('open_change'),\n",
    "    (pl.col('high') - pl.col('prev_high')).alias('high_change'),\n",
    "    (pl.col('low') - pl.col('prev_low')).alias('low_change'),\n",
    "    (pl.col('close') - pl.col('prev_close')).alias('close_change'),\n",
    "    ((pl.col('open') - pl.col('prev_open')) / pl.col('prev_open') * 100).alias('open_pct_change'),\n",
    "    ((pl.col('close') - pl.col('prev_close')) / pl.col('prev_close') * 100).alias('close_pct_change')\n",
    ")\n",
    "\n",
    "# Calculate rolling statistics\n",
    "df_features = df_features.with_columns(\n",
    "    pl.col('open').rolling_mean(3).alias('rolling_avg_open_3h'),\n",
    "    pl.col('close').rolling_mean(5).alias('rolling_avg_close_5h'),\n",
    "    pl.col('high').rolling_max(3).alias('rolling_max_high_3h'),\n",
    "    pl.col('low').rolling_min(3).alias('rolling_min_low_3h')\n",
    ")\n",
    "\n",
    "# Calculate volume features\n",
    "df_features = df_features.with_columns(\n",
    "    (pl.col('volume') - pl.col('prev_volume')).alias('volume_change'),\n",
    "    pl.col('volume').rolling_mean(3).alias('volume_ma_3h')\n",
    ")\n",
    "\n",
    "# Extract time-related features\n",
    "df_features = df_features.with_columns(\n",
    "    pl.col('date').dt.hour().alias('hour_of_day'),\n",
    "    pl.col('date').dt.weekday().alias('day_of_week')  # Corrected method\n",
    ")\n",
    "\n",
    "# Calculate ratios\n",
    "df_features = df_features.with_columns(\n",
    "    (pl.col('high') / pl.col('low')).alias('high_low_ratio'),\n",
    "    (pl.col('close') / pl.col('open')).alias('close_open_ratio')\n",
    ")\n",
    "\n",
    "# Calculate the highest close in the last 4, 8, 12, and 24 hours using rolling windows\n",
    "df_features = df_features.with_columns(\n",
    "    pl.col('close').rolling_max(window_size=4).alias('max_close_4h'),\n",
    "    pl.col('close').rolling_max(window_size=8).alias('max_close_8h'),\n",
    "    pl.col('close').rolling_max(window_size=12).alias('max_close_12h'),\n",
    "    pl.col('close').rolling_max(window_size=24).alias('max_close_24h')\n",
    ")\n",
    "\n",
    "# Calculate the min and max of the entire 'close' column\n",
    "max_close_all = df_features['close'].max()\n",
    "min_close_all = df_features['close'].min()\n",
    "\n",
    "# Calculate the difference from the current close to the max and min close\n",
    "df_features = df_features.with_columns(\n",
    "    (pl.col('close') - max_close_all).alias('diff_to_max_close'),\n",
    "    (pl.col('close') - min_close_all).alias('diff_to_min_close')\n",
    ")\n",
    "\n",
    "# Drop rows with any null values\n",
    "df_features = df_features.drop_nulls()\n",
    "\n",
    "df_features = df_features.with_columns(\n",
    "    pl.col('close').shift(-1).alias('next_close'),\n",
    ")\n",
    "\n",
    "# Print the updated DataFrame schema\n",
    "df_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing window 0 of 9987\n",
      "Window size [90000] | Time Elapsed: 604.600 seconds\n",
      "Average Prediction Error: 0.112 JPY | 0.076 % | Confidence Level: 66.807 % \n",
      "Average Prediction Error that less than avg change: 53.429 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>window_size</th>\n",
       "      <th>avg_val_rmse</th>\n",
       "      <th>windowed_confidence_level</th>\n",
       "      <th>var_val_rmse</th>\n",
       "      <th>avg_val_rmse_perc</th>\n",
       "      <th>var_val_rmse_perc</th>\n",
       "      <th>avg_train_rmse</th>\n",
       "      <th>var_train_rmse</th>\n",
       "      <th>avg_train_rmse_perc</th>\n",
       "      <th>var_train_rmse_perc</th>\n",
       "      <th>window_time</th>\n",
       "      <th>max_avg_val_rmse_perc</th>\n",
       "      <th>lower_count_perc</th>\n",
       "      <th>higher_count_perc</th>\n",
       "      <th>max_rmse_perc_lower</th>\n",
       "      <th>max_rmse_perc_higher</th>\n",
       "      <th>avg_rmse_perc_lower</th>\n",
       "      <th>avg_rmse_perc_higher</th>\n",
       "      <th>rmse_less_equal_60_perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90000</td>\n",
       "      <td>0.112434</td>\n",
       "      <td>66.806849</td>\n",
       "      <td>0.021617</td>\n",
       "      <td>0.076139</td>\n",
       "      <td>0.009891</td>\n",
       "      <td>0.130075</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.015261</td>\n",
       "      <td>8.184805e-08</td>\n",
       "      <td>604.600202</td>\n",
       "      <td>2.15428</td>\n",
       "      <td>50.705918</td>\n",
       "      <td>49.294082</td>\n",
       "      <td>1.380629</td>\n",
       "      <td>2.15428</td>\n",
       "      <td>0.07562</td>\n",
       "      <td>0.076673</td>\n",
       "      <td>53.429458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   window_size  avg_val_rmse  windowed_confidence_level  var_val_rmse  \\\n",
       "0        90000      0.112434                  66.806849      0.021617   \n",
       "\n",
       "   avg_val_rmse_perc  var_val_rmse_perc  avg_train_rmse  var_train_rmse  \\\n",
       "0           0.076139           0.009891        0.130075        0.000003   \n",
       "\n",
       "   avg_train_rmse_perc  var_train_rmse_perc  window_time  \\\n",
       "0             0.015261         8.184805e-08   604.600202   \n",
       "\n",
       "   max_avg_val_rmse_perc  lower_count_perc  higher_count_perc  \\\n",
       "0                2.15428         50.705918          49.294082   \n",
       "\n",
       "   max_rmse_perc_lower  max_rmse_perc_higher  avg_rmse_perc_lower  \\\n",
       "0             1.380629               2.15428              0.07562   \n",
       "\n",
       "   avg_rmse_perc_higher  rmse_less_equal_60_perc  \n",
       "0              0.076673                53.429458  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Separate df into features and target using Polars' select method\n",
    "features_df = df_features.select([col for col in df_features.columns if col not in ['datetime', 'next_close']])\n",
    "target_df = df_features['next_close']\n",
    "\n",
    "# Convert Polars DataFrame to NumPy arrays for processing\n",
    "X = features_df.to_numpy()\n",
    "y = target_df.to_numpy()\n",
    "\n",
    "# Specify parameters for the sliding window approach\n",
    "num_predictions = 1   # Number of rows to predict\n",
    "gap = 1               # Gap (number of rows to skip after each window)\n",
    "max_windows = 50      # Maximum number of windows to process\n",
    "set_limit = False     # Set this to False to process all windows\n",
    "\n",
    "# Define list of window sizes\n",
    "window_sizes = list(range(10000, 95001, 10000))\n",
    "# window_sizes = [90000]\n",
    "\n",
    "# List to store results\n",
    "results = []\n",
    "\n",
    "# Loop through each window size\n",
    "for window_size in window_sizes:\n",
    "    # Initiate lists to store RMSEs and percentages\n",
    "    all_val_rmse = []\n",
    "    all_val_rmse_perc = []\n",
    "    all_train_rmse = []\n",
    "    all_train_rmse_perc = []\n",
    "    total_window_times = 0  # Variable to store total time for all windows\n",
    "\n",
    "    # Counters and variables for prediction comparison to actual values\n",
    "    lower_count = 0\n",
    "    higher_count = 0\n",
    "    max_rmse_perc_lower = 0  # To store max RMSE% when prediction is lower than actual\n",
    "    max_rmse_perc_higher = 0  # To store max RMSE% when prediction is higher than actual\n",
    "\n",
    "    # Separate lists to store RMSE percentage for lower and higher predictions\n",
    "    lower_rmse_percs = []\n",
    "    higher_rmse_percs = []\n",
    "\n",
    "    # Separate lists to store val_rmse for lower and higher predictions\n",
    "    rmse_lower_perc = []  # To store RMSE when prediction is lower than actual\n",
    "    rmse_higher_perc = []  # To store RMSE when prediction is higher than actual\n",
    "\n",
    "    # Calculate the number of windows based on dataset size\n",
    "    num_windows = len(X) - window_size - num_predictions\n",
    "\n",
    "    # Apply maximum window limit if set\n",
    "    if set_limit:\n",
    "        num_windows = min(num_windows, max_windows)\n",
    "\n",
    "    # Loop through each sliding window with the gap applied\n",
    "    window_number = 0\n",
    "    while window_number < num_windows:\n",
    "        \n",
    "        if window_number % 20000 == 0:\n",
    "            print(f'Processing window {window_number} of {num_windows}')\n",
    "\n",
    "        start = window_number\n",
    "        end = start + window_size\n",
    "        X_train = X[start:end]\n",
    "        y_train = y[start:end]\n",
    "\n",
    "        # Normalize the training features\n",
    "        X_train_mean = np.mean(X_train, axis=0)\n",
    "        X_train_std = np.std(X_train, axis=0)\n",
    "        X_train_normalized = (X_train - X_train_mean) / X_train_std\n",
    "\n",
    "        # Get the column index for 'close' from features_df\n",
    "        close_index = features_df.columns.index('close')\n",
    "\n",
    "        # Normalize y_train using the mean and std of the 'close' column\n",
    "        close_mean = X_train[:, close_index].mean()\n",
    "        close_std = X_train[:, close_index].std()\n",
    "        y_train_normalized = (y_train - close_mean) / close_std\n",
    "\n",
    "        # Prepare validation data for prediction\n",
    "        X_val = X[end:end + num_predictions]\n",
    "        y_val = y[end:end + num_predictions]\n",
    "\n",
    "        # Normalize validation data using the statistics from the training set\n",
    "        X_val_normalized = (X_val - X_train_mean) / X_train_std\n",
    "\n",
    "        # Track the start time of the window processing\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Initialize and fit the model\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train_normalized, y_train_normalized)\n",
    "\n",
    "        # Predict on validation data\n",
    "        y_pred_val = model.predict(X_val_normalized)\n",
    "        # Predict on training data\n",
    "        y_pred_train = model.predict(X_train_normalized)\n",
    "\n",
    "        # Denormalize y_val, y_pred_train, and y_pred_val using the mean and std of 'close'\n",
    "        y_train_denorm = y_train * close_std + close_mean\n",
    "        y_pred_train_denorm = y_pred_train * close_std + close_mean\n",
    "        y_pred_val_denorm = y_pred_val * close_std + close_mean\n",
    "\n",
    "        # Calculate RMSE and RMSE percentage for validation\n",
    "        mse_val = np.mean((y_val - y_pred_val_denorm) ** 2)\n",
    "        rmse_val = np.sqrt(mse_val)\n",
    "        rmse_val_perc = (rmse_val / y_val)[0] * 100  # Convert to percentage\n",
    "\n",
    "        # Calculate RMSE for training\n",
    "        mse_train = np.mean((y_train - y_pred_train_denorm) ** 2)\n",
    "        rmse_train = np.sqrt(mse_train)\n",
    "        rmse_train_perc = ((y_train - y_pred_train_denorm) ** 2 / y_train).mean() * 100  # Convert to percentage\n",
    "\n",
    "        # Track the end time of the window processing\n",
    "        end_time = time.time()\n",
    "\n",
    "        # Calculate the time taken for this window\n",
    "        window_time = end_time - start_time\n",
    "        total_window_times += window_time  # Add the window time to the total time\n",
    "\n",
    "        # Append RMSEs and percentage errors\n",
    "        all_val_rmse.append(rmse_val)\n",
    "        all_val_rmse_perc.append(rmse_val_perc)\n",
    "        all_train_rmse.append(rmse_train)\n",
    "        all_train_rmse_perc.append(rmse_train_perc)\n",
    "\n",
    "        # Count predictions relative to actual values and update max RMSE percentage\n",
    "        if y_pred_val_denorm < y_val:\n",
    "            lower_count += 1\n",
    "            lower_rmse_percs.append(rmse_val_perc)  # Store RMSE percentage for lower predictions\n",
    "            max_rmse_perc_lower = max(max_rmse_perc_lower, rmse_val_perc)\n",
    "        elif y_pred_val_denorm > y_val:\n",
    "            higher_count += 1\n",
    "            higher_rmse_percs.append(rmse_val_perc)  # Store RMSE percentage for higher predictions\n",
    "            max_rmse_perc_higher = max(max_rmse_perc_higher, rmse_val_perc)\n",
    "\n",
    "        # Move to the next window based on the gap\n",
    "        window_number += gap\n",
    "\n",
    "    # Calculate percentage for lower and higher counts\n",
    "    lower_count_perc = (lower_count / num_windows) * 100\n",
    "    higher_count_perc = (higher_count / num_windows) * 100\n",
    "\n",
    "    # Calculate average RMSE percentage errors for lower and higher predictions\n",
    "    avg_rmse_perc_lower = np.mean(lower_rmse_percs) if lower_rmse_percs else 0\n",
    "    avg_rmse_perc_higher = np.mean(higher_rmse_percs) if higher_rmse_percs else 0\n",
    "\n",
    "    # Calculate average, max, min, and variance for validation and training RMSEs, percentages\n",
    "    avg_val_rmse = np.mean(all_val_rmse)\n",
    "    var_val_rmse = np.var(all_val_rmse)\n",
    "\n",
    "    avg_val_rmse_perc = np.mean(all_val_rmse_perc)\n",
    "    var_val_rmse_perc = np.var(all_val_rmse_perc)\n",
    "    max_avg_val_rmse_perc = np.max(all_val_rmse_perc)\n",
    "\n",
    "    avg_train_rmse = np.mean(all_train_rmse)\n",
    "    var_train_rmse = np.var(all_train_rmse)\n",
    "\n",
    "    avg_train_rmse_perc = np.mean(all_train_rmse_perc)\n",
    "    var_train_rmse_perc = np.var(all_train_rmse_perc)\n",
    "\n",
    "    # Calculate percentage of times RMSE is less than or equal to 0.0776\n",
    "    rmse_less_equal_avg_change = (np.sum(np.array(all_val_rmse) <= 0.0776) / len(all_val_rmse)) * 100\n",
    "\n",
    "    # Calculate percentage of times prediction is lower or equal to average RMSE\n",
    "    percentage_lower_equal_avg_rmse = (np.sum(np.array(all_val_rmse) <= avg_val_rmse) / len(all_val_rmse)) * 100\n",
    "\n",
    "    # Append results to the list with updated metric name\n",
    "    results.append({\n",
    "        'window_size': window_size,\n",
    "        'avg_val_rmse': avg_val_rmse,\n",
    "        'windowed_confidence_level': percentage_lower_equal_avg_rmse,  # Renamed metric\n",
    "        'var_val_rmse': var_val_rmse,\n",
    "        'avg_val_rmse_perc': avg_val_rmse_perc,\n",
    "        'var_val_rmse_perc': var_val_rmse_perc,\n",
    "        'avg_train_rmse': avg_train_rmse,\n",
    "        'var_train_rmse': var_train_rmse,\n",
    "        'avg_train_rmse_perc': avg_train_rmse_perc,\n",
    "        'var_train_rmse_perc': var_train_rmse_perc,\n",
    "        'window_time': total_window_times,\n",
    "        'max_avg_val_rmse_perc': max_avg_val_rmse_perc,\n",
    "        'lower_count_perc': lower_count_perc,\n",
    "        'higher_count_perc': higher_count_perc,\n",
    "        'max_rmse_perc_lower': max_rmse_perc_lower,\n",
    "        'max_rmse_perc_higher': max_rmse_perc_higher,\n",
    "        'avg_rmse_perc_lower': avg_rmse_perc_lower,\n",
    "        'avg_rmse_perc_higher': avg_rmse_perc_higher,\n",
    "        'rmse_less_equal_60_perc': rmse_less_equal_avg_change\n",
    "    })\n",
    "\n",
    "    # Print results for the current window size with the new name\n",
    "    print(f'Window size [{window_size}] | Time Elapsed: {total_window_times:.3f} seconds')\n",
    "    print(f'Average Prediction Error: {avg_val_rmse:.3f} JPY | {avg_val_rmse_perc:.3f} % | Confidence Level: {percentage_lower_equal_avg_rmse:.3f} % ')\n",
    "    print(f'Average Prediction Error that less than avg change: {rmse_less_equal_avg_change:.3f} %')\n",
    "# Optionally, you could convert the results to a DataFrame or CSV for further analysis\n",
    "results_summary = pd.DataFrame(results)\n",
    "results_summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
